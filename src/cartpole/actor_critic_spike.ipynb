{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Actor-Critic spike\n",
    "\n",
    "Plan:\n",
    "- Spike Actor-Critic\n",
    "- Quick test on a Gym env\n",
    "- Update requirements.txt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports & setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Essential tools"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic setup\n",
    "# from typing import Tuple"
   ]
  },
  {
   "source": [
    "### Examine Gym environments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from gym import envs\n",
    "print(envs.registry.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Reproducible gym environments\n",
    "env.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(500,\n",
       " 475.0,\n",
       " Discrete(2),\n",
       " Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32))"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Check environment details\n",
    "# CartPole-v0 is 200, 195.0\n",
    "# CartPole-v1 is 500, 475.0\n",
    "env.spec.max_episode_steps, env.spec.reward_threshold, env.action_space, env.observation_space"
   ]
  },
  {
   "source": [
    "### Import PyTorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x131347210>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check for CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Reproducible results\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "source": [
    "## Actor-Critic base class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from actor_critic import ActorCritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ActorCritic(\n  (actor): Sequential(\n    (0): Linear(in_features=4, out_features=12, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=12, out_features=2, bias=True)\n    (3): Softmax(dim=1)\n  )\n  (critic): Sequential(\n    (0): Linear(in_features=4, out_features=12, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=12, out_features=1, bias=True)\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "# Parameters based on environment:\n",
    "NUM_OBSERVATIONS: int = env.observation_space.shape[0] # input\n",
    "NUM_ACTIONS: int = env.action_space.n # output\n",
    "# NUM_ACTIONS, NUM_OBSERVATIONS\n",
    "\n",
    "ac = ActorCritic(NUM_OBSERVATIONS, NUM_ACTIONS, (12, 12, 15, 20)).to(device)\n",
    "print(ac)\n",
    "# print(vars(ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "18.0\n",
      "20.0\n",
      "9.0\n",
      "24.0\n",
      "22.0\n",
      "48.0\n",
      "11.0\n",
      "24.0\n",
      "20.0\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "# One episode\n",
    "def do_one_episode(env: gym.Env):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        state = torch.unsqueeze(torch.FloatTensor(state), 0).to(device)\n",
    "        probability_dist, values = ac(state)\n",
    "        action_to_take = probability_dist.sample()\n",
    "        next_state, reward, done, _ = env.step(action_to_take.cpu().detach().numpy()[0])\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "    return total_reward\n",
    "\n",
    "# Test for 10 episodes\n",
    "cartpole = gym.make(\"CartPole-v1\")\n",
    "for i in range(10):\n",
    "    reward = do_one_episode(cartpole)\n",
    "    print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}