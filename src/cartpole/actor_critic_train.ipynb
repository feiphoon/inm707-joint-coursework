{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0ec04c10a3ef611ea2836b5ff833f0501e0dcfc8e0500f516ccda9246622a0e8e",
   "display_name": "Python 3.8.5 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Actor-Critic: A2C training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports & setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Essential tools"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic setup\n",
    "import math\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Callable\n",
    "from collections import namedtuple\n",
    "\n",
    "# For logging and saving results\n",
    "from datetime import datetime\n",
    "import os\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "sys.prefix == sys.base_prefix \n"
   ]
  },
  {
   "source": [
    "### Examine Gym environments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# from gym import envs\n",
    "# print(envs.registry.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(500,\n",
       " 475.0,\n",
       " Discrete(2),\n",
       " Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32))"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# Smoke test\n",
    "#env = gym.make(\"CartPole-v1\")\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "# # Check environment details\n",
    "# CartPole-v0 is 200, 195.0\n",
    "# CartPole-v1 is 500, 475.0\n",
    "# Pong-v0 is 10000, None, 6, 255\n",
    "env.spec.max_episode_steps, env.spec.reward_threshold, env.action_space, env.observation_space\n",
    "\n",
    "# Rememeber to make reproducible gym environments\n",
    "# env.seed(0)"
   ]
  },
  {
   "source": [
    "### Import PyTorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x143fe9330>"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Check for CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Reproducible results\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install stable_baselines3==1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import only for multiprocessing\n",
    "import stable_baselines3\n",
    "from stable_baselines3.common.env_util import SubprocVecEnv\n",
    "from stable_baselines3.common.utils import set_random_seed"
   ]
  },
  {
   "source": [
    "### Import local modules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from actor_critic import ActorCritic\n",
    "from utils import stringify_dict"
   ]
  },
  {
   "source": [
    "## Set up evaluation\n",
    "\n",
    "Gym CartPole V0 & V1 description:\n",
    "\n",
    ">A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center.\n",
    "\n",
    "Four terminating states for CartPole-v1:\n",
    "- env.spec.max_episode_steps 500\n",
    "- env.spec.reward_threshold 475.0\n",
    "- pole is more than 15 degrees from vertical\n",
    "- the cart moves more than 2.4 units from the centre\n",
    "\n",
    "https://towardsdatascience.com/understanding-actor-critic-methods-931b97b6df3f\n",
    "\n",
    "Doing A2C, a single worker variant of A3C.\n",
    "- backprop\n",
    "- keep the hidden layer simple (1)\n",
    "- ADAM as loss function (RMSprop was very stable as recommended in stable-baselines3, but reward was very poor)\n",
    "- reward step size/evaluation step size 5\n",
    "\n",
    "Hyperparameters:\n",
    "(values from Deep Reinforcement Learning Hands-On, Maxim Lapan)\n",
    "- num of envs used [6, 12, 24]\n",
    "- num_episodes [50000, 100000]\n",
    "- learning rate [0.001, 0.002, 0.003]\n",
    "- hidden layers [(32, 32), (64, 64), (128, 128)]\n",
    "- max gradient/gradient clipping [0.1]\n",
    "- Adam optimiser epsilon [default]\n",
    "- reward step bootstrapping [5] (10 was very careless)\n",
    "- ~~entropy reg weight [0.001, 0.002, 0.003]~~\n",
    "- ~~value coefficient [0.1, 0.3, 0.5]~~\n",
    "\n",
    "Performance analysis:\n",
    "- Reward\n",
    "- policy loss\n",
    "- value loss\n",
    "- overall loss\n",
    "- ~~No. of timesteps per episode (before terminating state)~~ No need as timesteps == rewards\n",
    "- No need for wallclock time as we don't want to compare this for now.\n",
    "\n",
    "Eduard = MSI RX 2080, 6 cores Intel Core i5 9600KF\n",
    "Fei = 6 cores AMD Ryzen 5 3600, I'm not going to install ROCm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One episode/test run/logging rewards\n",
    "def sample_one_episode(env: gym.Env, model: ActorCritic):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        state = torch.unsqueeze(torch.FloatTensor(state), 0).to(device)\n",
    "        probability_dist, values = model(state)\n",
    "        action_to_take = probability_dist.sample()\n",
    "        next_state, reward, done, _ = env.step(action_to_take.cpu().detach().numpy()[0])\n",
    "        state = next_state\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "    return total_reward\n",
    "    \n",
    "def calculate_returns(next_value: torch.Tensor, rewards: List[torch.FloatTensor], masks: List[int], gamma: float) -> List[torch.Tensor]:\n",
    "    calculated_returns = []\n",
    "    # Calculate the accumulated returns \n",
    "    # from the number of \"reward steps to update\".\n",
    "    # Reset R to the next_value first.\n",
    "    R = next_value\n",
    "\n",
    "    # Calculate discounted return & go backwards\n",
    "    for _ in range(len(rewards))[::-1]:\n",
    "        R = rewards[_] + gamma * R * masks[_]\n",
    "        # Push return value R\n",
    "        calculated_returns.insert(0, R)\n",
    "    return calculated_returns\n",
    "\n",
    "def plot_rewards_episodes(episode_idx: int, experiment_rewards: list):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title(f\"Last reward of {experiment_rewards[-1]} after {episode_idx} episodes\")\n",
    "    plt.xlabel(\"Per 1000 episodes\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.plot(experiment_rewards)\n",
    "    plt.show()\n",
    "\n",
    "# From: https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/multiprocessing_rl.ipynb\n",
    "\n",
    "def make_env(env_id: str, rank: int, seed: int = 0) -> Callable:\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "    \n",
    "    :param env_id: (str) the environment ID\n",
    "    :param num_env: (int) the number of environment you wish to have in subprocesses\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    :return: (Callable)\n",
    "    \"\"\"\n",
    "    def _init() -> gym.Env:\n",
    "        env = gym.make(env_id)\n",
    "        env.seed(seed + rank)\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = namedtuple(\"Results\", \"min_reward, max_reward, reward_variance, mean_reward, mean_actor_loss, mean_critic_loss, mean_entropy_loss, mean_overall_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters based on environment:\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "NUM_OBSERVATIONS: int = env.observation_space.shape[0] # input\n",
    "NUM_ACTIONS: int = env.action_space.n # output\n",
    "\n",
    "# Hyperparameters\n",
    "NUM_ENV_LIST: list = [6, 12, 24]\n",
    "NUM_EPISODES_LIST: list = [50000, 100000]\n",
    "LEARNING_RATE_LIST: list = [0.001, 0.002, 0.003]\n",
    "HIDDEN_LAYER_LIST: list = [(32, 32), (64, 64), (128, 128)]\n",
    "\n",
    "# Later hyperparameters to try and fix critic\n",
    "ENTROPY_REG_WEIGHT_LIST: list = [0.001, 0.002, 0.003]\n",
    "VALUE_COEFFICIENT_LIST: list = [0.1, 0.3, 0.5]\n",
    "\n",
    "ENTROPY_REG_WEIGHT: float = 0.001 # Entropy regularisation weight/beta/coefficient\n",
    "VALUE_LOSS_COEFFICIENT: float = 1.0 # Have seen this as 0.5 and 0.1, we will choose the lower\n",
    "NUM_REWARD_STEPS: int = 5\n",
    "GAMMA = 0.9\n",
    "MAX_GRADIENT = 0.1\n",
    "\n",
    "ENV_NAME = \"CartPole-v1\"\n",
    "#ENV_NAME = \"CartPole-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 1440x360 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"330.255937pt\" version=\"1.1\" viewBox=\"0 0 373.902482 330.255937\" width=\"373.902482pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-08T07:52:58.584228</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 330.255937 \nL 373.902482 330.255937 \nL 373.902482 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 38.467187 293.735625 \nL 366.702482 293.735625 \nL 366.702482 21.935625 \nL 38.467187 21.935625 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 53.386974 293.735625 \nL 53.386974 21.935625 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g style=\"fill:#262626;\" transform=\"translate(50.606505 307.893437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 266 2259 \nQ 266 3072 433 3567 \nQ 600 4063 929 4331 \nQ 1259 4600 1759 4600 \nQ 2128 4600 2406 4451 \nQ 2684 4303 2865 4023 \nQ 3047 3744 3150 3342 \nQ 3253 2941 3253 2259 \nQ 3253 1453 3087 958 \nQ 2922 463 2592 192 \nQ 2263 -78 1759 -78 \nQ 1097 -78 719 397 \nQ 266 969 266 2259 \nz\nM 844 2259 \nQ 844 1131 1108 757 \nQ 1372 384 1759 384 \nQ 2147 384 2411 759 \nQ 2675 1134 2675 2259 \nQ 2675 3391 2411 3762 \nQ 2147 4134 1753 4134 \nQ 1366 4134 1134 3806 \nQ 844 3388 844 2259 \nz\n\" id=\"ArialMT-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 99.294008 293.735625 \nL 99.294008 21.935625 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g style=\"fill:#262626;\" transform=\"translate(96.513539 307.893437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 3222 541 \nL 3222 0 \nL 194 0 \nQ 188 203 259 391 \nQ 375 700 629 1000 \nQ 884 1300 1366 1694 \nQ 2113 2306 2375 2664 \nQ 2638 3022 2638 3341 \nQ 2638 3675 2398 3904 \nQ 2159 4134 1775 4134 \nQ 1369 4134 1125 3890 \nQ 881 3647 878 3216 \nL 300 3275 \nQ 359 3922 746 4261 \nQ 1134 4600 1788 4600 \nQ 2447 4600 2831 4234 \nQ 3216 3869 3216 3328 \nQ 3216 3053 3103 2787 \nQ 2991 2522 2730 2228 \nQ 2469 1934 1863 1422 \nQ 1356 997 1212 845 \nQ 1069 694 975 541 \nL 3222 541 \nz\n\" id=\"ArialMT-32\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 145.201042 293.735625 \nL 145.201042 21.935625 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g style=\"fill:#262626;\" transform=\"translate(142.420573 307.893437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2069 0 \nL 2069 1097 \nL 81 1097 \nL 81 1613 \nL 2172 4581 \nL 2631 4581 \nL 2631 1613 \nL 3250 1613 \nL 3250 1097 \nL 2631 1097 \nL 2631 0 \nL 2069 0 \nz\nM 2069 1613 \nL 2069 3678 \nL 634 1613 \nL 2069 1613 \nz\n\" id=\"ArialMT-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 191.108076 293.735625 \nL 191.108076 21.935625 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g style=\"fill:#262626;\" transform=\"translate(188.327607 307.893437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 3184 3459 \nL 2625 3416 \nQ 2550 3747 2413 3897 \nQ 2184 4138 1850 4138 \nQ 1581 4138 1378 3988 \nQ 1113 3794 959 3422 \nQ 806 3050 800 2363 \nQ 1003 2672 1297 2822 \nQ 1591 2972 1913 2972 \nQ 2475 2972 2870 2558 \nQ 3266 2144 3266 1488 \nQ 3266 1056 3080 686 \nQ 2894 316 2569 119 \nQ 2244 -78 1831 -78 \nQ 1128 -78 684 439 \nQ 241 956 241 2144 \nQ 241 3472 731 4075 \nQ 1159 4600 1884 4600 \nQ 2425 4600 2770 4297 \nQ 3116 3994 3184 3459 \nz\nM 888 1484 \nQ 888 1194 1011 928 \nQ 1134 663 1356 523 \nQ 1578 384 1822 384 \nQ 2178 384 2434 671 \nQ 2691 959 2691 1453 \nQ 2691 1928 2437 2201 \nQ 2184 2475 1800 2475 \nQ 1419 2475 1153 2201 \nQ 888 1928 888 1484 \nz\n\" id=\"ArialMT-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 237.01511 293.735625 \nL 237.01511 21.935625 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <g style=\"fill:#262626;\" transform=\"translate(234.234641 307.893437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1131 2484 \nQ 781 2613 612 2850 \nQ 444 3088 444 3419 \nQ 444 3919 803 4259 \nQ 1163 4600 1759 4600 \nQ 2359 4600 2725 4251 \nQ 3091 3903 3091 3403 \nQ 3091 3084 2923 2848 \nQ 2756 2613 2416 2484 \nQ 2838 2347 3058 2040 \nQ 3278 1734 3278 1309 \nQ 3278 722 2862 322 \nQ 2447 -78 1769 -78 \nQ 1091 -78 675 323 \nQ 259 725 259 1325 \nQ 259 1772 486 2073 \nQ 713 2375 1131 2484 \nz\nM 1019 3438 \nQ 1019 3113 1228 2906 \nQ 1438 2700 1772 2700 \nQ 2097 2700 2305 2904 \nQ 2513 3109 2513 3406 \nQ 2513 3716 2298 3927 \nQ 2084 4138 1766 4138 \nQ 1444 4138 1231 3931 \nQ 1019 3725 1019 3438 \nz\nM 838 1322 \nQ 838 1081 952 856 \nQ 1066 631 1291 507 \nQ 1516 384 1775 384 \nQ 2178 384 2440 643 \nQ 2703 903 2703 1303 \nQ 2703 1709 2433 1975 \nQ 2163 2241 1756 2241 \nQ 1359 2241 1098 1978 \nQ 838 1716 838 1322 \nz\n\" id=\"ArialMT-38\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 282.922144 293.735625 \nL 282.922144 21.935625 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <g style=\"fill:#262626;\" transform=\"translate(277.361207 307.893437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2384 0 \nL 1822 0 \nL 1822 3584 \nQ 1619 3391 1289 3197 \nQ 959 3003 697 2906 \nL 697 3450 \nQ 1169 3672 1522 3987 \nQ 1875 4303 2022 4600 \nL 2384 4600 \nL 2384 0 \nz\n\" id=\"ArialMT-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 328.829178 293.735625 \nL 328.829178 21.935625 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 12 -->\n      <g style=\"fill:#262626;\" transform=\"translate(323.268241 307.893437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- Per 1000 episodes -->\n     <g style=\"fill:#262626;\" transform=\"translate(160.891085 321.068437)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 494 0 \nL 494 4581 \nL 2222 4581 \nQ 2678 4581 2919 4538 \nQ 3256 4481 3484 4323 \nQ 3713 4166 3852 3881 \nQ 3991 3597 3991 3256 \nQ 3991 2672 3619 2267 \nQ 3247 1863 2275 1863 \nL 1100 1863 \nL 1100 0 \nL 494 0 \nz\nM 1100 2403 \nL 2284 2403 \nQ 2872 2403 3119 2622 \nQ 3366 2841 3366 3238 \nQ 3366 3525 3220 3729 \nQ 3075 3934 2838 4000 \nQ 2684 4041 2272 4041 \nL 1100 4041 \nL 1100 2403 \nz\n\" id=\"ArialMT-50\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2694 1069 \nL 3275 997 \nQ 3138 488 2766 206 \nQ 2394 -75 1816 -75 \nQ 1088 -75 661 373 \nQ 234 822 234 1631 \nQ 234 2469 665 2931 \nQ 1097 3394 1784 3394 \nQ 2450 3394 2872 2941 \nQ 3294 2488 3294 1666 \nQ 3294 1616 3291 1516 \nL 816 1516 \nQ 847 969 1125 678 \nQ 1403 388 1819 388 \nQ 2128 388 2347 550 \nQ 2566 713 2694 1069 \nz\nM 847 1978 \nL 2700 1978 \nQ 2663 2397 2488 2606 \nQ 2219 2931 1791 2931 \nQ 1403 2931 1139 2672 \nQ 875 2413 847 1978 \nz\n\" id=\"ArialMT-65\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 416 0 \nL 416 3319 \nL 922 3319 \nL 922 2816 \nQ 1116 3169 1280 3281 \nQ 1444 3394 1641 3394 \nQ 1925 3394 2219 3213 \nL 2025 2691 \nQ 1819 2813 1613 2813 \nQ 1428 2813 1281 2702 \nQ 1134 2591 1072 2394 \nQ 978 2094 978 1738 \nL 978 0 \nL 416 0 \nz\n\" id=\"ArialMT-72\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 422 -1272 \nL 422 3319 \nL 934 3319 \nL 934 2888 \nQ 1116 3141 1344 3267 \nQ 1572 3394 1897 3394 \nQ 2322 3394 2647 3175 \nQ 2972 2956 3137 2557 \nQ 3303 2159 3303 1684 \nQ 3303 1175 3120 767 \nQ 2938 359 2589 142 \nQ 2241 -75 1856 -75 \nQ 1575 -75 1351 44 \nQ 1128 163 984 344 \nL 984 -1272 \nL 422 -1272 \nz\nM 931 1641 \nQ 931 1000 1190 694 \nQ 1450 388 1819 388 \nQ 2194 388 2461 705 \nQ 2728 1022 2728 1688 \nQ 2728 2322 2467 2637 \nQ 2206 2953 1844 2953 \nQ 1484 2953 1207 2617 \nQ 931 2281 931 1641 \nz\n\" id=\"ArialMT-70\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 425 3934 \nL 425 4581 \nL 988 4581 \nL 988 3934 \nL 425 3934 \nz\nM 425 0 \nL 425 3319 \nL 988 3319 \nL 988 0 \nL 425 0 \nz\n\" id=\"ArialMT-69\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 197 991 \nL 753 1078 \nQ 800 744 1014 566 \nQ 1228 388 1613 388 \nQ 2000 388 2187 545 \nQ 2375 703 2375 916 \nQ 2375 1106 2209 1216 \nQ 2094 1291 1634 1406 \nQ 1016 1563 777 1677 \nQ 538 1791 414 1992 \nQ 291 2194 291 2438 \nQ 291 2659 392 2848 \nQ 494 3038 669 3163 \nQ 800 3259 1026 3326 \nQ 1253 3394 1513 3394 \nQ 1903 3394 2198 3281 \nQ 2494 3169 2634 2976 \nQ 2775 2784 2828 2463 \nL 2278 2388 \nQ 2241 2644 2061 2787 \nQ 1881 2931 1553 2931 \nQ 1166 2931 1000 2803 \nQ 834 2675 834 2503 \nQ 834 2394 903 2306 \nQ 972 2216 1119 2156 \nQ 1203 2125 1616 2013 \nQ 2213 1853 2448 1751 \nQ 2684 1650 2818 1456 \nQ 2953 1263 2953 975 \nQ 2953 694 2789 445 \nQ 2625 197 2315 61 \nQ 2006 -75 1616 -75 \nQ 969 -75 630 194 \nQ 291 463 197 991 \nz\n\" id=\"ArialMT-73\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 213 1659 \nQ 213 2581 725 3025 \nQ 1153 3394 1769 3394 \nQ 2453 3394 2887 2945 \nQ 3322 2497 3322 1706 \nQ 3322 1066 3130 698 \nQ 2938 331 2570 128 \nQ 2203 -75 1769 -75 \nQ 1072 -75 642 372 \nQ 213 819 213 1659 \nz\nM 791 1659 \nQ 791 1022 1069 705 \nQ 1347 388 1769 388 \nQ 2188 388 2466 706 \nQ 2744 1025 2744 1678 \nQ 2744 2294 2464 2611 \nQ 2184 2928 1769 2928 \nQ 1347 2928 1069 2612 \nQ 791 2297 791 1659 \nz\n\" id=\"ArialMT-6f\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2575 0 \nL 2575 419 \nQ 2259 -75 1647 -75 \nQ 1250 -75 917 144 \nQ 584 363 401 755 \nQ 219 1147 219 1656 \nQ 219 2153 384 2558 \nQ 550 2963 881 3178 \nQ 1213 3394 1622 3394 \nQ 1922 3394 2156 3267 \nQ 2391 3141 2538 2938 \nL 2538 4581 \nL 3097 4581 \nL 3097 0 \nL 2575 0 \nz\nM 797 1656 \nQ 797 1019 1065 703 \nQ 1334 388 1700 388 \nQ 2069 388 2326 689 \nQ 2584 991 2584 1609 \nQ 2584 2291 2321 2609 \nQ 2059 2928 1675 2928 \nQ 1300 2928 1048 2622 \nQ 797 2316 797 1656 \nz\n\" id=\"ArialMT-64\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#ArialMT-50\"/>\n      <use x=\"66.699219\" xlink:href=\"#ArialMT-65\"/>\n      <use x=\"122.314453\" xlink:href=\"#ArialMT-72\"/>\n      <use x=\"155.615234\" xlink:href=\"#ArialMT-20\"/>\n      <use x=\"183.398438\" xlink:href=\"#ArialMT-31\"/>\n      <use x=\"239.013672\" xlink:href=\"#ArialMT-30\"/>\n      <use x=\"294.628906\" xlink:href=\"#ArialMT-30\"/>\n      <use x=\"350.244141\" xlink:href=\"#ArialMT-30\"/>\n      <use x=\"405.859375\" xlink:href=\"#ArialMT-20\"/>\n      <use x=\"433.642578\" xlink:href=\"#ArialMT-65\"/>\n      <use x=\"489.257812\" xlink:href=\"#ArialMT-70\"/>\n      <use x=\"544.873047\" xlink:href=\"#ArialMT-69\"/>\n      <use x=\"567.089844\" xlink:href=\"#ArialMT-73\"/>\n      <use x=\"617.089844\" xlink:href=\"#ArialMT-6f\"/>\n      <use x=\"672.705078\" xlink:href=\"#ArialMT-64\"/>\n      <use x=\"728.320312\" xlink:href=\"#ArialMT-65\"/>\n      <use x=\"783.935547\" xlink:href=\"#ArialMT-73\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 38.467187 265.873282 \nL 366.702482 265.873282 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 20 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.345312 269.452188)scale(0.1 -0.1)\">\n       <use xlink:href=\"#ArialMT-32\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 38.467187 231.411509 \nL 366.702482 231.411509 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 30 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.345312 234.990416)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 269 1209 \nL 831 1284 \nQ 928 806 1161 595 \nQ 1394 384 1728 384 \nQ 2125 384 2398 659 \nQ 2672 934 2672 1341 \nQ 2672 1728 2419 1979 \nQ 2166 2231 1775 2231 \nQ 1616 2231 1378 2169 \nL 1441 2663 \nQ 1497 2656 1531 2656 \nQ 1891 2656 2178 2843 \nQ 2466 3031 2466 3422 \nQ 2466 3731 2256 3934 \nQ 2047 4138 1716 4138 \nQ 1388 4138 1169 3931 \nQ 950 3725 888 3313 \nL 325 3413 \nQ 428 3978 793 4289 \nQ 1159 4600 1703 4600 \nQ 2078 4600 2393 4439 \nQ 2709 4278 2876 4000 \nQ 3044 3722 3044 3409 \nQ 3044 3113 2884 2869 \nQ 2725 2625 2413 2481 \nQ 2819 2388 3044 2092 \nQ 3269 1797 3269 1353 \nQ 3269 753 2831 336 \nQ 2394 -81 1725 -81 \nQ 1122 -81 723 278 \nQ 325 638 269 1209 \nz\n\" id=\"ArialMT-33\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-33\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 38.467187 196.949737 \nL 366.702482 196.949737 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 40 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.345312 200.528643)scale(0.1 -0.1)\">\n       <use xlink:href=\"#ArialMT-34\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 38.467187 162.487964 \nL 366.702482 162.487964 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 50 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.345312 166.066871)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 266 1200 \nL 856 1250 \nQ 922 819 1161 601 \nQ 1400 384 1738 384 \nQ 2144 384 2425 690 \nQ 2706 997 2706 1503 \nQ 2706 1984 2436 2262 \nQ 2166 2541 1728 2541 \nQ 1456 2541 1237 2417 \nQ 1019 2294 894 2097 \nL 366 2166 \nL 809 4519 \nL 3088 4519 \nL 3088 3981 \nL 1259 3981 \nL 1013 2750 \nQ 1425 3038 1878 3038 \nQ 2478 3038 2890 2622 \nQ 3303 2206 3303 1553 \nQ 3303 931 2941 478 \nQ 2500 -78 1738 -78 \nQ 1113 -78 717 272 \nQ 322 622 266 1200 \nz\n\" id=\"ArialMT-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-35\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 38.467187 128.026192 \nL 366.702482 128.026192 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_13\">\n      <!-- 60 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.345312 131.605098)scale(0.1 -0.1)\">\n       <use xlink:href=\"#ArialMT-36\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 38.467187 93.564419 \nL 366.702482 93.564419 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_14\">\n      <!-- 70 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.345312 97.143325)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 303 3981 \nL 303 4522 \nL 3269 4522 \nL 3269 4084 \nQ 2831 3619 2401 2847 \nQ 1972 2075 1738 1259 \nQ 1569 684 1522 0 \nL 944 0 \nQ 953 541 1156 1306 \nQ 1359 2072 1739 2783 \nQ 2119 3494 2547 3981 \nL 303 3981 \nz\n\" id=\"ArialMT-37\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-37\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 38.467187 59.102647 \nL 366.702482 59.102647 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_15\">\n      <!-- 80 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.345312 62.681553)scale(0.1 -0.1)\">\n       <use xlink:href=\"#ArialMT-38\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#pe939cdb653)\" d=\"M 38.467187 24.640874 \nL 366.702482 24.640874 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"text_16\">\n      <!-- 90 -->\n      <g style=\"fill:#262626;\" transform=\"translate(20.345312 28.21978)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 350 1059 \nL 891 1109 \nQ 959 728 1153 556 \nQ 1347 384 1650 384 \nQ 1909 384 2104 503 \nQ 2300 622 2425 820 \nQ 2550 1019 2634 1356 \nQ 2719 1694 2719 2044 \nQ 2719 2081 2716 2156 \nQ 2547 1888 2255 1720 \nQ 1963 1553 1622 1553 \nQ 1053 1553 659 1965 \nQ 266 2378 266 3053 \nQ 266 3750 677 4175 \nQ 1088 4600 1706 4600 \nQ 2153 4600 2523 4359 \nQ 2894 4119 3086 3673 \nQ 3278 3228 3278 2384 \nQ 3278 1506 3087 986 \nQ 2897 466 2520 194 \nQ 2144 -78 1638 -78 \nQ 1100 -78 759 220 \nQ 419 519 350 1059 \nz\nM 2653 3081 \nQ 2653 3566 2395 3850 \nQ 2138 4134 1775 4134 \nQ 1400 4134 1122 3828 \nQ 844 3522 844 3034 \nQ 844 2597 1108 2323 \nQ 1372 2050 1759 2050 \nQ 2150 2050 2401 2323 \nQ 2653 2597 2653 3081 \nz\n\" id=\"ArialMT-39\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-39\"/>\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- Reward -->\n     <g style=\"fill:#262626;\" transform=\"translate(14.357812 175.06375)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 503 0 \nL 503 4581 \nL 2534 4581 \nQ 3147 4581 3465 4457 \nQ 3784 4334 3975 4021 \nQ 4166 3709 4166 3331 \nQ 4166 2844 3850 2509 \nQ 3534 2175 2875 2084 \nQ 3116 1969 3241 1856 \nQ 3506 1613 3744 1247 \nL 4541 0 \nL 3778 0 \nL 3172 953 \nQ 2906 1366 2734 1584 \nQ 2563 1803 2427 1890 \nQ 2291 1978 2150 2013 \nQ 2047 2034 1813 2034 \nL 1109 2034 \nL 1109 0 \nL 503 0 \nz\nM 1109 2559 \nL 2413 2559 \nQ 2828 2559 3062 2645 \nQ 3297 2731 3419 2920 \nQ 3541 3109 3541 3331 \nQ 3541 3656 3305 3865 \nQ 3069 4075 2559 4075 \nL 1109 4075 \nL 1109 2559 \nz\n\" id=\"ArialMT-52\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1034 0 \nL 19 3319 \nL 600 3319 \nL 1128 1403 \nL 1325 691 \nQ 1338 744 1497 1375 \nL 2025 3319 \nL 2603 3319 \nL 3100 1394 \nL 3266 759 \nL 3456 1400 \nL 4025 3319 \nL 4572 3319 \nL 3534 0 \nL 2950 0 \nL 2422 1988 \nL 2294 2553 \nL 1622 0 \nL 1034 0 \nz\n\" id=\"ArialMT-77\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2588 409 \nQ 2275 144 1986 34 \nQ 1697 -75 1366 -75 \nQ 819 -75 525 192 \nQ 231 459 231 875 \nQ 231 1119 342 1320 \nQ 453 1522 633 1644 \nQ 813 1766 1038 1828 \nQ 1203 1872 1538 1913 \nQ 2219 1994 2541 2106 \nQ 2544 2222 2544 2253 \nQ 2544 2597 2384 2738 \nQ 2169 2928 1744 2928 \nQ 1347 2928 1158 2789 \nQ 969 2650 878 2297 \nL 328 2372 \nQ 403 2725 575 2942 \nQ 747 3159 1072 3276 \nQ 1397 3394 1825 3394 \nQ 2250 3394 2515 3294 \nQ 2781 3194 2906 3042 \nQ 3031 2891 3081 2659 \nQ 3109 2516 3109 2141 \nL 3109 1391 \nQ 3109 606 3145 398 \nQ 3181 191 3288 0 \nL 2700 0 \nQ 2613 175 2588 409 \nz\nM 2541 1666 \nQ 2234 1541 1622 1453 \nQ 1275 1403 1131 1340 \nQ 988 1278 909 1158 \nQ 831 1038 831 891 \nQ 831 666 1001 516 \nQ 1172 366 1500 366 \nQ 1825 366 2078 508 \nQ 2331 650 2450 897 \nQ 2541 1088 2541 1459 \nL 2541 1666 \nz\n\" id=\"ArialMT-61\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#ArialMT-52\"/>\n      <use x=\"72.216797\" xlink:href=\"#ArialMT-65\"/>\n      <use x=\"127.832031\" xlink:href=\"#ArialMT-77\"/>\n      <use x=\"200.048828\" xlink:href=\"#ArialMT-61\"/>\n      <use x=\"255.664062\" xlink:href=\"#ArialMT-72\"/>\n      <use x=\"288.964844\" xlink:href=\"#ArialMT-64\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pe939cdb653)\" d=\"M 53.386974 255.190132 \nL 76.340491 278.968755 \nL 99.294008 281.036462 \nL 122.247525 281.38108 \nL 145.201042 242.094659 \nL 168.154559 213.491388 \nL 191.108076 118.376895 \nL 214.061593 135.263164 \nL 237.01511 104.247569 \nL 259.968627 114.930718 \nL 282.922144 34.29017 \nL 305.875661 35.324024 \nL 328.829178 102.179862 \nL 351.782696 52.55491 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 38.467187 293.735625 \nL 38.467187 21.935625 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 366.702482 293.735625 \nL 366.702482 21.935625 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 38.467187 293.735625 \nL 366.702482 293.735625 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 38.467187 21.935625 \nL 366.702482 21.935625 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_18\">\n    <!-- Last reward of 81.9 after 14000 episodes -->\n    <g style=\"fill:#262626;\" transform=\"translate(93.52171 15.935625)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 469 0 \nL 469 4581 \nL 1075 4581 \nL 1075 541 \nL 3331 541 \nL 3331 0 \nL 469 0 \nz\n\" id=\"ArialMT-4c\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 1650 503 \nL 1731 6 \nQ 1494 -44 1306 -44 \nQ 1000 -44 831 53 \nQ 663 150 594 308 \nQ 525 466 525 972 \nL 525 2881 \nL 113 2881 \nL 113 3319 \nL 525 3319 \nL 525 4141 \nL 1084 4478 \nL 1084 3319 \nL 1650 3319 \nL 1650 2881 \nL 1084 2881 \nL 1084 941 \nQ 1084 700 1114 631 \nQ 1144 563 1211 522 \nQ 1278 481 1403 481 \nQ 1497 481 1650 503 \nz\n\" id=\"ArialMT-74\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 556 0 \nL 556 2881 \nL 59 2881 \nL 59 3319 \nL 556 3319 \nL 556 3672 \nQ 556 4006 616 4169 \nQ 697 4388 901 4523 \nQ 1106 4659 1475 4659 \nQ 1713 4659 2000 4603 \nL 1916 4113 \nQ 1741 4144 1584 4144 \nQ 1328 4144 1222 4034 \nQ 1116 3925 1116 3625 \nL 1116 3319 \nL 1763 3319 \nL 1763 2881 \nL 1116 2881 \nL 1116 0 \nL 556 0 \nz\n\" id=\"ArialMT-66\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 581 0 \nL 581 641 \nL 1222 641 \nL 1222 0 \nL 581 0 \nz\n\" id=\"ArialMT-2e\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#ArialMT-4c\"/>\n     <use x=\"55.615234\" xlink:href=\"#ArialMT-61\"/>\n     <use x=\"111.230469\" xlink:href=\"#ArialMT-73\"/>\n     <use x=\"161.230469\" xlink:href=\"#ArialMT-74\"/>\n     <use x=\"189.013672\" xlink:href=\"#ArialMT-20\"/>\n     <use x=\"216.796875\" xlink:href=\"#ArialMT-72\"/>\n     <use x=\"250.097656\" xlink:href=\"#ArialMT-65\"/>\n     <use x=\"305.712891\" xlink:href=\"#ArialMT-77\"/>\n     <use x=\"377.929688\" xlink:href=\"#ArialMT-61\"/>\n     <use x=\"433.544922\" xlink:href=\"#ArialMT-72\"/>\n     <use x=\"466.845703\" xlink:href=\"#ArialMT-64\"/>\n     <use x=\"522.460938\" xlink:href=\"#ArialMT-20\"/>\n     <use x=\"550.244141\" xlink:href=\"#ArialMT-6f\"/>\n     <use x=\"605.859375\" xlink:href=\"#ArialMT-66\"/>\n     <use x=\"633.642578\" xlink:href=\"#ArialMT-20\"/>\n     <use x=\"661.425781\" xlink:href=\"#ArialMT-38\"/>\n     <use x=\"717.041016\" xlink:href=\"#ArialMT-31\"/>\n     <use x=\"772.65625\" xlink:href=\"#ArialMT-2e\"/>\n     <use x=\"800.439453\" xlink:href=\"#ArialMT-39\"/>\n     <use x=\"856.054688\" xlink:href=\"#ArialMT-20\"/>\n     <use x=\"883.837891\" xlink:href=\"#ArialMT-61\"/>\n     <use x=\"939.453125\" xlink:href=\"#ArialMT-66\"/>\n     <use x=\"967.236328\" xlink:href=\"#ArialMT-74\"/>\n     <use x=\"995.019531\" xlink:href=\"#ArialMT-65\"/>\n     <use x=\"1050.634766\" xlink:href=\"#ArialMT-72\"/>\n     <use x=\"1083.935547\" xlink:href=\"#ArialMT-20\"/>\n     <use x=\"1111.71875\" xlink:href=\"#ArialMT-31\"/>\n     <use x=\"1167.333984\" xlink:href=\"#ArialMT-34\"/>\n     <use x=\"1222.949219\" xlink:href=\"#ArialMT-30\"/>\n     <use x=\"1278.564453\" xlink:href=\"#ArialMT-30\"/>\n     <use x=\"1334.179688\" xlink:href=\"#ArialMT-30\"/>\n     <use x=\"1389.794922\" xlink:href=\"#ArialMT-20\"/>\n     <use x=\"1417.578125\" xlink:href=\"#ArialMT-65\"/>\n     <use x=\"1473.193359\" xlink:href=\"#ArialMT-70\"/>\n     <use x=\"1528.808594\" xlink:href=\"#ArialMT-69\"/>\n     <use x=\"1551.025391\" xlink:href=\"#ArialMT-73\"/>\n     <use x=\"1601.025391\" xlink:href=\"#ArialMT-6f\"/>\n     <use x=\"1656.640625\" xlink:href=\"#ArialMT-64\"/>\n     <use x=\"1712.255859\" xlink:href=\"#ArialMT-65\"/>\n     <use x=\"1767.871094\" xlink:href=\"#ArialMT-73\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe939cdb653\">\n   <rect height=\"271.8\" width=\"328.235294\" x=\"38.467187\" y=\"21.935625\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-ff8ae33ff912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m                             \u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                             \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                             \u001b[0;31m# entropy += probability_distribution.entropy().mean()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Logging stuff\n",
    "RESULTS_PATH = \"results\"\n",
    "EXP_TYPE = \"train-a2c\"\n",
    "dt_now = datetime.now()\n",
    "dt_str = dt_now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "OUTPUT_PATH = os.path.join(RESULTS_PATH, ENV_NAME, EXP_TYPE, dt_str)\n",
    "\n",
    "if not os.path.isdir(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "for num_env in list(NUM_ENV_LIST):\n",
    "    for num_episodes in list(NUM_EPISODES_LIST):\n",
    "        for lr in list(LEARNING_RATE_LIST):\n",
    "            for hl in list(HIDDEN_LAYER_LIST):\n",
    "                for vc in list(VALUE_COEFFICIENT_LIST):\n",
    "                    # Reset hyperparameter list\n",
    "                    HYPERPARAMETER_LIST = {}\n",
    "\n",
    "                    HYPERPARAMETER_LIST[\"num_env\"] = num_env\n",
    "                    HYPERPARAMETER_LIST[\"num_episodes\"] = num_episodes\n",
    "                    HYPERPARAMETER_LIST[\"learning_rate\"] = lr\n",
    "                    HYPERPARAMETER_LIST[\"hidden_layers\"] = hl\n",
    "                    HYPERPARAMETER_LIST[\"value_coefficient\"] = vc\n",
    "                    # print(stringify_dict(HYPERPARAMETER_LIST))\n",
    "\n",
    "                    HYPERPARAMETERS_STR = stringify_dict(HYPERPARAMETER_LIST)\n",
    "                    FILE_NAME = f\"{HYPERPARAMETERS_STR}\".replace(\":\", \"\").replace(\" \", \"\").replace(\",\", \"-\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "                    LOG_FILE_NAME = FILE_NAME + \".txt\"\n",
    "                    PLOT_FILE_NAME = FILE_NAME\n",
    "                    MODEL_FILE_NAME = FILE_NAME + \".pt\"\n",
    "\n",
    "                    # Time code\n",
    "                    start_time = timeit.default_timer()\n",
    "\n",
    "                    # Create the vectorized environment\n",
    "                    envs = SubprocVecEnv([make_env(ENV_NAME, i) for i in range(num_env)])\n",
    "\n",
    "                    model = ActorCritic(num_inputs=NUM_OBSERVATIONS, num_outputs=NUM_ACTIONS, hidden_layer_config=hl).to(device)\n",
    "                    optimiser = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "                    # Set up results logging\n",
    "                    episode_idx: int = 0\n",
    "                    experiment_rewards: list = []\n",
    "                    experiment_actor_loss: list = []\n",
    "                    experiment_critic_loss: list = []\n",
    "                    experiment_overall_loss: list = []\n",
    "                    experiment_entropy_loss: list = []\n",
    "                    experiment_rewards_var: list = []\n",
    "\n",
    "                    state = envs.reset()\n",
    "\n",
    "                    while episode_idx < num_episodes:\n",
    "\n",
    "                        # Structures to hold our records for updating\n",
    "                        log_probs: list = []\n",
    "                        values: list = []\n",
    "                        rewards: list = []\n",
    "\n",
    "                        # entropy: int = 0 # reset Entropy\n",
    "                        entropy_loss: float = 0\n",
    "                        # Our thresholding tensors which \"turn off\" returns\n",
    "                        # for the next_value (changes them to zero),\n",
    "                        # if the episode terminates before the 500 max \n",
    "                        # timesteps on Cartpole-v1 are reached.\n",
    "                        masks: list = []\n",
    "\n",
    "                        for _ in range(NUM_REWARD_STEPS):\n",
    "                            state = torch.FloatTensor(state).to(device)\n",
    "                            probability_distribution, state_values = model(state)\n",
    "                            action_to_take = probability_distribution.sample()\n",
    "\n",
    "                            next_state, reward, done, _ = envs.step(action_to_take.cpu().numpy())\n",
    "                            state = next_state\n",
    "\n",
    "                            # Update all the things:\n",
    "                            values.append(state_values)\n",
    "\n",
    "                            log_prob = probability_distribution.log_prob(action_to_take)\n",
    "                            log_probs.append(log_prob)\n",
    "\n",
    "                            rewards.append(torch.unsqueeze(torch.FloatTensor(reward),1).to(device))\n",
    "\n",
    "                            # entropy += probability_distribution.entropy().mean()\n",
    "                            entropy_loss += -probability_distribution.entropy().mean()\n",
    "\n",
    "                            # 1 - False = 1; 1 - True = 0\n",
    "                            # 1 - returns for next value continue to be calculated.\n",
    "                            masks.append(torch.unsqueeze(torch.FloatTensor(1 - done),1).to(device))\n",
    "\n",
    "                            # Increment episode counter\n",
    "                            episode_idx += 1\n",
    "\n",
    "                            if episode_idx % 1000 == 0:\n",
    "                                experiment_rewards.append(np.mean([sample_one_episode(env, model) for _ in range(10)]))\n",
    "                                experiment_rewards_var.append(np.std([sample_one_episode(env, model) for _ in range(10)]))\n",
    "                                experiment_entropy_loss.append(entropy_loss)\n",
    "                                plot_rewards_episodes(episode_idx, experiment_rewards)\n",
    "\n",
    "                        next_state = torch.FloatTensor(next_state).to(device)\n",
    "                        _, next_state_value = model(next_state)\n",
    "                        returns = calculate_returns(next_state_value, rewards, masks, GAMMA)\n",
    "\n",
    "                        # Run the next code with no gradients kept, so that \n",
    "                        # this can be a bit more efficient.\n",
    "                        # with torch.no_grad():\n",
    "                        # Update everything\n",
    "                        log_probs= torch.cat(log_probs)\n",
    "                        returns = torch.cat(returns).detach()\n",
    "                        values = torch.cat(values)\n",
    "\n",
    "                        advantage = returns - values\n",
    "\n",
    "                        # Or policy loss\n",
    "                        actor_loss = -(log_probs * advantage.detach()).mean()\n",
    "                        experiment_actor_loss.append(actor_loss)\n",
    "\n",
    "                        # Or value loss - using MSE\n",
    "                        critic_loss = advantage.pow(2).mean()\n",
    "                        experiment_critic_loss.append(critic_loss)\n",
    "\n",
    "                        overall_loss = actor_loss + (VALUE_LOSS_COEFFICIENT * critic_loss) + (ENTROPY_REG_WEIGHT * entropy_loss)\n",
    "                        experiment_overall_loss.append(overall_loss)\n",
    "\n",
    "                        # Clear gradients in optimiser to zero\n",
    "                        # so that we don't accumulate on\n",
    "                        # past gradients.\n",
    "                        optimiser.zero_grad()\n",
    "\n",
    "                        # Propagate loss/weights backwards\n",
    "                        overall_loss.backward()\n",
    "\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRADIENT)\n",
    "                        # Update model parameters\n",
    "                        optimiser.step()\n",
    "\n",
    "                    # End timer\n",
    "                    WALL_TIME = timeit.default_timer() - start_time\n",
    "\n",
    "                    # Plot rewards\n",
    "                    plt.plot(experiment_rewards);\n",
    "                    plt.title(f\"A2C agent rewards on {ENV_NAME} for {num_episodes} episodes\");\n",
    "                    plt.xlabel(\"Per 1000 episodes\");\n",
    "                    plt.ylabel(\"Reward\");\n",
    "                    plt.ylim([0, 500]);\n",
    "                    # plt.ylim([0, 200]); # for CartPole-v0\n",
    "                    plt.xlim([0, 100]);\n",
    "\n",
    "                    last_reward = (num_episodes/1000, experiment_rewards[-1])\n",
    "                    enumerated_rewards = list(enumerate(experiment_rewards))\n",
    "                    min_reward = min(enumerated_rewards, key=itemgetter(1))\n",
    "                    max_reward = max(enumerated_rewards, key=itemgetter(1))\n",
    "\n",
    "                    plt.annotate(f\"Last {last_reward[1]}\", last_reward)\n",
    "                    plt.annotate(f\"Min {min_reward[1]}\", min_reward)\n",
    "                    plt.annotate(f\"Max {max_reward[1]}\", max_reward)\n",
    "                    plt.savefig(os.path.join(OUTPUT_PATH, PLOT_FILE_NAME + \"_rewards.png\"), dpi=300, bbox_inches=\"tight\");\n",
    "                    plt.show();\n",
    "\n",
    "\n",
    "                    # Plot rewards variance\n",
    "                    plt.plot(experiment_rewards_var);\n",
    "                    plt.title(f\"A2C agent rewards variance on {ENV_NAME} for {num_episodes} episodes\");\n",
    "                    plt.xlabel(\"Per 1000 episodes\");\n",
    "                    plt.ylabel(\"Reward variance\");\n",
    "                    plt.ylim([0, 200]);\n",
    "                    plt.xlim([0, 100]);\n",
    "\n",
    "                    last_reward_var = (num_episodes/1000, experiment_rewards_var[-1])\n",
    "                    enumerated_rewards_var = list(enumerate(experiment_rewards_var))\n",
    "                    min_reward_var = min(enumerated_rewards_var, key=itemgetter(1))\n",
    "                    max_reward_var = max(enumerated_rewards_var, key=itemgetter(1))\n",
    "\n",
    "                    plt.annotate(f\"Last {last_reward_var[1]}\", last_reward_var)\n",
    "                    plt.annotate(f\"Min {min_reward_var[1]}\", min_reward_var)\n",
    "                    plt.annotate(f\"Max {max_reward_var[1]}\", max_reward_var)\n",
    "                    plt.savefig(os.path.join(OUTPUT_PATH, PLOT_FILE_NAME + \"_rewards_var.png\"), dpi=300, bbox_inches=\"tight\");\n",
    "                    plt.show();\n",
    "\n",
    "\n",
    "                    # Plot actor loss\n",
    "                    experiment_actor_loss_list = [loss.item() for loss in experiment_actor_loss]\n",
    "                    sns.lineplot(data=experiment_actor_loss_list);\n",
    "                    plt.title(f\"A2C agent last actor loss of {experiment_actor_loss_list[-1]} after {num_episodes} episodes\")\n",
    "                    plt.xlabel(\"Updates\");\n",
    "                    plt.ylabel(\"Actor Loss\");\n",
    "                    plt.ylim([-3, 3]);\n",
    "                    plt.xlim([0, 20000]);\n",
    "                    plt.savefig(os.path.join(OUTPUT_PATH, PLOT_FILE_NAME + \"_actor_loss.png\"), dpi=300, bbox_inches=\"tight\");\n",
    "                    plt.show();\n",
    "\n",
    "\n",
    "                    # Plot critic loss\n",
    "                    experiment_critic_loss_list = [loss.item() for loss in experiment_critic_loss]\n",
    "                    sns.lineplot(data=experiment_critic_loss_list);\n",
    "                    plt.title(f\"A2C agent last critic loss of {experiment_critic_loss_list[-1]} after {num_episodes} episodes\")\n",
    "                    plt.xlabel(\"Updates\");\n",
    "                    plt.ylabel(\"Critic Loss\");\n",
    "                    plt.ylim([0, 40]);\n",
    "                    plt.xlim([0, 20000]);\n",
    "                    plt.savefig(os.path.join(OUTPUT_PATH, PLOT_FILE_NAME + \"_critic_loss.png\"), dpi=300, bbox_inches=\"tight\");\n",
    "                    plt.show();\n",
    "\n",
    "\n",
    "                    # Plot overall loss\n",
    "                    experiment_overall_loss_list = [loss.item() for loss in experiment_overall_loss]\n",
    "                    sns.lineplot(data=experiment_overall_loss_list);\n",
    "                    plt.title(f\"A2C agent last overall loss of {experiment_overall_loss_list[-1]} after {num_episodes} episodes\")\n",
    "                    plt.xlabel(\"Updates\");\n",
    "                    plt.ylabel(\"Overall Loss\");\n",
    "                    plt.ylim([0, 40]);\n",
    "                    plt.xlim([0, 20000]);\n",
    "                    plt.savefig(os.path.join(OUTPUT_PATH, PLOT_FILE_NAME + \"_overall_loss.png\"), dpi=300, bbox_inches=\"tight\");\n",
    "                    plt.show();\n",
    "\n",
    "\n",
    "                    # Plot entropy loss\n",
    "                    experiment_entropy_loss_list = [loss.item() for loss in experiment_entropy_loss]\n",
    "                    sns.lineplot(data=experiment_entropy_loss_list);\n",
    "                    plt.title(f\"Last entropy loss of {experiment_entropy_loss_list[-1]} after {num_episodes} episodes\")\n",
    "                    plt.xlabel(\"Updates\");\n",
    "                    plt.ylabel(\"Entropy Loss\");\n",
    "                    plt.ylim([-5, 5]);\n",
    "                    plt.xlim([0, 100]);\n",
    "                    plt.savefig(os.path.join(OUTPUT_PATH, PLOT_FILE_NAME + \"_entropy_loss.png\"), dpi=300, bbox_inches=\"tight\");\n",
    "                    plt.show();\n",
    "\n",
    "                    results = Results(min(experiment_rewards), max(experiment_rewards), np.std(experiment_rewards), np.mean(experiment_rewards), np.mean(experiment_actor_loss_list), np.mean(experiment_critic_loss_list), np.mean(experiment_entropy_loss_list), np.mean(experiment_overall_loss_list))\n",
    "\n",
    "                    with open(os.path.join(OUTPUT_PATH, LOG_FILE_NAME), \"w\") as f:\n",
    "                        f.write(f\"datetime:{dt_str}\\n\")\n",
    "                        f.write(f\"hyperparameters:{HYPERPARAMETERS_STR}\\n\")\n",
    "                        tidy_results = stringify_dict(results._asdict()).replace(\"-\", \":\")\n",
    "                        f.write(f\"results:{tidy_results}\\n\")\n",
    "                        f.write(f\"wall_time:{WALL_TIME}\\n\")\n",
    "\n",
    "                    with open(os.path.join(OUTPUT_PATH, \"all_results.txt\"), \"a\") as f:\n",
    "                        f.write(f\"\\n==================================\\n\")\n",
    "                        f.write(f\"datetime:{dt_str}\\n\")\n",
    "                        f.write(f\"hyperparameters:{HYPERPARAMETERS_STR}\\n\")\n",
    "                        tidy_results = stringify_dict(results._asdict()).replace(\"-\", \":\")\n",
    "                        f.write(f\"results:{tidy_results}\\n\")\n",
    "                        f.write(f\"wall_time:{WALL_TIME}\\n\")\n",
    "                        f.write(f\"\\n==================================\\n\")\n",
    "\n",
    "\n",
    "                    # Specify a path to save model\n",
    "                    MODEL_PATH = os.path.join(OUTPUT_PATH, MODEL_FILE_NAME)\n",
    "                    torch.save(model, MODEL_PATH)\n",
    "\n",
    "                    # Close envs\n",
    "                    envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16.7, 115.5, 25.52153631739281, 72.428)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "min(experiment_rewards), max(experiment_rewards), np.std(experiment_rewards), np.mean(experiment_rewards)\n",
    "# VALUE_LOSS_COEFFICIENT = 0.1\n",
    "# 85.6 218.6, 32.21718150304275\n",
    "\n",
    "# VALUE_LOSS_COEFFICIENT = 0.5\n",
    "# (81.8, 242.8, 35.98530639024768, 162.418)\n",
    "\n",
    "# NUM_EPISODES = 100000\n",
    "# (101.4, 310.5, 34.232210723235504, 168.143)\n",
    "\n",
    "# VALUE_LOSS_COEFFICIENT = 0.01\n",
    "# (84.4, 291.4, 41.10671160528412, 161.66899999999998)\n",
    "\n",
    "# NUM_REWARD_STEPS: int = 10\n",
    "# (37.9, 168.4, 22.67719777662134, 81.899)\n",
    "\n",
    "# lr=0.0001\n",
    "# (74.7, 224.5, 29.891392389783388, 145.119)\n",
    "\n",
    "# I changed nothing\n",
    "# (80.9, 214.8, 29.989488341750683, 133.78300000000002)\n",
    "\n",
    "# Adam lr: 0.002, gradient clipping: 1 \n",
    "# The policy is weighted at 1.0, value function at 0.6, entropy at 0.001.\n",
    "# We go for 10-step bootstrapping, eight workers, and a 0.95 tau.\n",
    "# (18.0, 468.1, 94.37116402800169, 223.33999999999997)\n",
    "\n",
    "# 12 workers, 32x32\n",
    "# (20.2, 428.8, 93.23209095585061, 224.504)\n",
    "# 12 workers, 128 x 128\n",
    "# (23.8, 483.7, 110.44132099898115, 258.804)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}