datetime:20210407-003658
hyperparameters:num_env:6, num_episodes:50000, learning_rate:0.003, hidden_layers:(128, 128)
results:min_reward:24.7, max_reward:180.4, reward_variance:34.29441709666458, mean_reward:114.46599999999998, mean_actor_loss::0.10668688546174736, mean_critic_loss:1.5808493029471469, mean_entropy_loss::3.0576866722106932, mean_overall_loss:1.4711043702567812
wall_time:131.294766083
