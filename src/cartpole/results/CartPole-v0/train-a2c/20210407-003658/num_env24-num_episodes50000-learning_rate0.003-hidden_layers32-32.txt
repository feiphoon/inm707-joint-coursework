datetime:20210407-003658
hyperparameters:num_env:24, num_episodes:50000, learning_rate:0.003, hidden_layers:(32, 32)
results:min_reward:19.9, max_reward:188.8, reward_variance:37.291737905332326, mean_reward:128.02200000000002, mean_actor_loss::0.020363444544266168, mean_critic_loss:1.1310211463779212, mean_entropy_loss::3.0533159446716307, mean_overall_loss:1.107591518997727
wall_time:218.65137718500046
