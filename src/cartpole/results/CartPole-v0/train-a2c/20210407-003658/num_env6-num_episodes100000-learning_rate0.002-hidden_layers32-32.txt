datetime:20210407-003658
hyperparameters:num_env:6, num_episodes:100000, learning_rate:0.002, hidden_layers:(32, 32)
results:min_reward:19.8, max_reward:174.4, reward_variance:29.330023593580687, mean_reward:99.24599999999998, mean_actor_loss::0.12093695477699053, mean_critic_loss:1.7871885658707047, mean_entropy_loss::3.0934554076194765, mean_overall_loss:1.6631386462166846
wall_time:251.88810266200016
