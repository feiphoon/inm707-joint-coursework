datetime:20210407-003658
hyperparameters:num_env:12, num_episodes:50000, learning_rate:0.001, hidden_layers:(32, 32)
results:min_reward:20.3, max_reward:184.4, reward_variance:35.57334080459692, mean_reward:98.568, mean_actor_loss::0.047564331012166575, mean_critic_loss:1.8250155710602063, mean_entropy_loss::3.158116202354431, mean_overall_loss:1.7742898982964224
wall_time:155.62644731399996
