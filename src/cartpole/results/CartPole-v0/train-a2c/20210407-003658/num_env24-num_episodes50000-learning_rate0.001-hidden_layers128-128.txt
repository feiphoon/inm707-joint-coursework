datetime:20210407-003658
hyperparameters:num_env:24, num_episodes:50000, learning_rate:0.001, hidden_layers:(128, 128)
results:min_reward:20.1, max_reward:200.0, reward_variance:45.285101700228076, mean_reward:129.358, mean_actor_loss::0.012285210698028038, mean_critic_loss:1.132179642482428, mean_entropy_loss::3.0922760581970214, mean_overall_loss:1.116816323356796
wall_time:218.30603228100154
