datetime:20210407-003658
hyperparameters:num_env:12, num_episodes:50000, learning_rate:0.003, hidden_layers:(128, 128)
results:min_reward:28.4, max_reward:196.3, reward_variance:34.871088081675914, mean_reward:135.904, mean_actor_loss::0.0587384928717358, mean_critic_loss:1.192310676358192, mean_entropy_loss::3.005770788192749, mean_overall_loss:1.130551537220308
wall_time:166.11256609599968
