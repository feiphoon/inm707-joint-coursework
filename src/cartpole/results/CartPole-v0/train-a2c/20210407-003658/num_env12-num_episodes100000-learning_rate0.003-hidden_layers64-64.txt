datetime:20210407-003658
hyperparameters:num_env:12, num_episodes:100000, learning_rate:0.003, hidden_layers:(64, 64)
results:min_reward:28.5, max_reward:177.7, reward_variance:30.332983697618666, mean_reward:124.21000000000002, mean_actor_loss::0.06360603519686446, mean_critic_loss:1.1019448233266056, mean_entropy_loss::2.994209725856781, mean_overall_loss:1.0353139314318482
wall_time:316.83657122599925
