datetime:20210407-003658
hyperparameters:num_env:12, num_episodes:100000, learning_rate:0.003, hidden_layers:(128, 128)
results:min_reward:32.4, max_reward:195.2, reward_variance:31.901867202406823, mean_reward:126.43699999999997, mean_actor_loss::0.061882684420753335, mean_critic_loss:1.0781327347003251, mean_entropy_loss::2.9699885272979736, mean_overall_loss:1.013248599778884
wall_time:319.8593564590001
