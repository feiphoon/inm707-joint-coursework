datetime:20210407-190232
hyperparameters:num_env:12, num_episodes:50000, learning_rate:0.001, hidden_layers:(32, 32), value_coefficient:0.1
results:min_reward:19.3, max_reward:167.9, reward_variance:41.031767254165395, mean_reward:101.874, mean_actor_loss::0.042016862959737, mean_critic_loss:1.7385024838560377, mean_entropy_loss::3.174691162109375, mean_overall_loss:1.6933161783084971
wall_time:127.36736900299911
