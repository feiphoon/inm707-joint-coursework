datetime:20210407-190232
hyperparameters:num_env:6, num_episodes:100000, learning_rate:0.001, hidden_layers:(128, 128), value_coefficient:0.3
results:min_reward:24.5, max_reward:243.8, reward_variance:37.89181763916849, mean_reward:108.266, mean_actor_loss::0.11747997410601428, mean_critic_loss:1.7372200963078095, mean_entropy_loss::3.129317464828491, mean_overall_loss:1.6166101141813851
wall_time:253.54493217899926
