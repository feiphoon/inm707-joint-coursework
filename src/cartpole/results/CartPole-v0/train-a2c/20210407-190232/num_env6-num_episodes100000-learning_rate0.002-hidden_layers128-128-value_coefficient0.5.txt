datetime:20210407-190232
hyperparameters:num_env:6, num_episodes:100000, learning_rate:0.002, hidden_layers:(128, 128), value_coefficient:0.5
results:min_reward:18.0, max_reward:247.6, reward_variance:38.66249991917232, mean_reward:114.05, mean_actor_loss::0.1135419555397757, mean_critic_loss:1.591258503636288, mean_entropy_loss::3.0734099841117857, mean_overall_loss:1.4746589204352816
wall_time:335.3593188140003
