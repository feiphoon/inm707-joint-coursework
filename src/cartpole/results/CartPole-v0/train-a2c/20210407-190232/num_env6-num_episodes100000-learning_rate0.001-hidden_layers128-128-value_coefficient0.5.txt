datetime:20210407-190232
hyperparameters:num_env:6, num_episodes:100000, learning_rate:0.001, hidden_layers:(128, 128), value_coefficient:0.5
results:min_reward:15.1, max_reward:191.4, reward_variance:35.19290864648729, mean_reward:105.891, mean_actor_loss::0.11756652566124383, mean_critic_loss:1.7390037456314411, mean_entropy_loss::3.121529026031494, mean_overall_loss:1.6183097800765187
wall_time:236.9670271699997
