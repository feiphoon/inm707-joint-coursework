datetime:20210407-190232
hyperparameters:num_env:6, num_episodes:50000, learning_rate:0.002, hidden_layers:(32, 32), value_coefficient:0.3
results:min_reward:20.8, max_reward:180.9, reward_variance:37.822632853887896, mean_reward:101.638, mean_actor_loss::0.11734715516806585, mean_critic_loss:2.004489069643457, mean_entropy_loss::3.161427035331726, mean_overall_loss:1.8839765894789715
wall_time:122.89143706300001
