datetime:20210407-190232
hyperparameters:num_env:12, num_episodes:50000, learning_rate:0.001, hidden_layers:(128, 128), value_coefficient:0.5
results:min_reward:18.6, max_reward:221.0, reward_variance:47.188978586106316, mean_reward:124.89, mean_actor_loss::0.057189669891916435, mean_critic_loss:1.4183265824787668, mean_entropy_loss::3.1282020807266235, mean_overall_loss:1.358015857267566
wall_time:131.95036063499902
