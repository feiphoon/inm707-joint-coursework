datetime:20210407-190232
hyperparameters:num_env:6, num_episodes:100000, learning_rate:0.003, hidden_layers:(32, 32), value_coefficient:0.1
results:min_reward:21.9, max_reward:230.9, reward_variance:41.08776820417483, mean_reward:115.85199999999999, mean_actor_loss::0.1169328478590296, mean_critic_loss:1.664084009133982, mean_entropy_loss::3.071163992881775, mean_overall_loss:1.5440708867223176
wall_time:362.1085446870002
