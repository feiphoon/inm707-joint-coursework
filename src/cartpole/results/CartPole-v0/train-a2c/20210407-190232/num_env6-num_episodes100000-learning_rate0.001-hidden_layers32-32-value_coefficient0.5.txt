datetime:20210407-190232
hyperparameters:num_env:6, num_episodes:100000, learning_rate:0.001, hidden_layers:(32, 32), value_coefficient:0.5
results:min_reward:20.1, max_reward:173.6, reward_variance:31.81275560211658, mean_reward:92.85900000000001, mean_actor_loss::0.12452151767903588, mean_critic_loss:2.082560481640064, mean_entropy_loss::3.1619131898880006, mean_overall_loss:1.954855606451357
wall_time:247.94727445199987
