datetime:20210405-225734
hyperparameters:num_env:6, num_episodes:100000, learning_rate:0.003, hidden_layers:(64, 64)
results:min_reward:14.8, max_reward:228.6, reward_variance:38.00534436102375, mean_reward:109.06, mean_actor_loss::0.1069086133091348, mean_critic_loss:1.4736034866106928, mean_entropy_loss::3.0353297138214113, mean_overall_loss:1.3636263501549606
wall_time:253.050133069999
