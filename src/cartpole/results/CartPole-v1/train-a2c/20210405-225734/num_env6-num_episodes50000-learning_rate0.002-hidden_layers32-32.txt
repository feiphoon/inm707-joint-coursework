datetime:20210405-225734
hyperparameters:num_env:6, num_episodes:50000, learning_rate:0.002, hidden_layers:(32, 32)
results:min_reward:18.5, max_reward:205.1, reward_variance:43.213831119214596, mean_reward:95.74, mean_actor_loss::0.11038184957677025, mean_critic_loss:1.9183033384934387, mean_entropy_loss::3.1587304306030273, mean_overall_loss:1.8047618829886312
wall_time:134.3010969499992
