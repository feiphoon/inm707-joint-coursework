datetime:20210405-225734
hyperparameters:num_env:12, num_episodes:100000, learning_rate:0.001, hidden_layers:(64, 64)
results:min_reward:16.0, max_reward:302.9, reward_variance:45.15003694350648, mean_reward:136.358, mean_actor_loss::0.05767223890930456, mean_critic_loss:1.1467526544158202, mean_entropy_loss::3.1252109098434446, mean_overall_loss:1.085959206678241
wall_time:326.5587803439994
