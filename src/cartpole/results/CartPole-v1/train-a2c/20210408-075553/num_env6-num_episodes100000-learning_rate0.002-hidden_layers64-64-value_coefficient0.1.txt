datetime:20210408-075553
hyperparameters:num_env:6, num_episodes:100000, learning_rate:0.002, hidden_layers:(64, 64), value_coefficient:0.1
results:min_reward:15.2, max_reward:209.3, reward_variance:36.26139484355228, mean_reward:105.16199999999999, mean_actor_loss::0.11390132535942449, mean_critic_loss:1.6298304908042565, mean_entropy_loss::3.0660512709617613, mean_overall_loss:1.5128345935071994
wall_time:280.0366602009999
