{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from policies import basic_policy, random_policy,intelligent_policy\n",
    "from maze import Maze\n",
    "from exp_orchestrator import run_experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_environments_per_size=10\n",
    "n_runs_per_environments=10\n",
    "\n",
    "plot_params = { basic_policy: {'label': 'basic_policy', 'color':'r'}, \n",
    "              random_policy: {'label': 'random_policy', 'color':'b'},\n",
    "              intelligent_policy: {'label': 'intelligent_policy', 'color':'g'}\n",
    "              }\n",
    "\n",
    "for policy in [basic_policy, random_policy, intelligent_policy]:\n",
    "\n",
    "    mean_reward = []\n",
    "    std_reward = []\n",
    "    \n",
    "    for size_envir in range(5,100,5):\n",
    "\n",
    "        total_rewards = []\n",
    "\n",
    "        for n_envir in range(n_environments_per_size):\n",
    "\n",
    "            maze = Maze(size_envir)\n",
    "        \n",
    "            all_total_rewards, _, _, _ = run_experiments(maze, policy, n_runs_per_environments)\n",
    "            \n",
    "            total_rewards += all_total_rewards\n",
    "            \n",
    "        mean_reward.append( np.mean(total_rewards) )\n",
    "        std_reward.append( np.std(total_rewards) )\n",
    "        \n",
    "    mean_reward = np.asarray(mean_reward)\n",
    "    std_reward = np.asarray(std_reward)\n",
    "    \n",
    "    plt.plot(range(5, 100, 5), mean_reward, 'o'+plot_params[policy]['color'])\n",
    "    plt.plot(range(5, 100, 5), mean_reward, color = plot_params[policy]['color'], label = plot_params[policy]['label'] )\n",
    "    plt.fill_between(range(5, 100, 5), mean_reward - std_reward/2, mean_reward + std_reward/2,\n",
    "                 color=plot_params[policy]['color'], alpha=0.2)\n",
    "\n",
    "plt.xlabel('Environment size')\n",
    "plt.ylabel('Average reward')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ]
}